{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loasd JSON file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>Barely better than Gabbert? He was significant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>No!! NOO!!!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt\n",
       "0  sports  Barely better than Gabbert? He was significant...\n",
       "1  sports  Fuck the ducks and the Angels! But welcome to ...\n",
       "2  sports  Should have drafted more WRs.\\n\\n- Matt Millen...\n",
       "3  sports            [Done](https://i.imgur.com/2YZ90pm.jpg)\n",
       "4  sports                                      No!! NOO!!!!!"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    " \n",
    "data = pd.read_json('categorized-comments.jsonl', lines=True)\n",
    "df = pd.DataFrame(data)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all text to lower case letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barely better than gabbert? he was significant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fuck the ducks and the angels! but welcome to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>should have drafted more wrs.\\n\\n- matt millen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[done](https://i.imgur.com/2yz90pm.jpg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no!! noo!!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ding dong the kaepers gone!!!!!! yes!!!! frida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yup\\n\\nthat would be best case scenario. still...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i think larry kruger made a good point on knbr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>this is great to have two well-regarded rb coa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7-9 next season confirmed.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt\n",
       "0  barely better than gabbert? he was significant...\n",
       "1  fuck the ducks and the angels! but welcome to ...\n",
       "2  should have drafted more wrs.\\n\\n- matt millen...\n",
       "3            [done](https://i.imgur.com/2yz90pm.jpg)\n",
       "4                                      no!! noo!!!!!\n",
       "5  ding dong the kaepers gone!!!!!! yes!!!! frida...\n",
       "6  yup\\n\\nthat would be best case scenario. still...\n",
       "7  i think larry kruger made a good point on knbr...\n",
       "8  this is great to have two well-regarded rb coa...\n",
       "9                         7-9 next season confirmed."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = df['cat']\n",
    "df_cat = pd.DataFrame(df_cat)\n",
    "df= df['txt'].str.lower()\n",
    "df = pd.DataFrame(df)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all punctuation from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-07822b49f9ce>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"txt\"] = df['txt'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barely better than gabbert he was significantl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fuck the ducks and the angels but welcome to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>should have drafted more wrs\\n\\n matt millen p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>donehttpsiimgurcom2yz90pmjpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no noo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt\n",
       "0  barely better than gabbert he was significantl...\n",
       "1  fuck the ducks and the angels but welcome to a...\n",
       "2  should have drafted more wrs\\n\\n matt millen p...\n",
       "3                       donehttpsiimgurcom2yz90pmjpg\n",
       "4                                             no noo"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"txt\"] = df['txt'].str.replace('[^\\w\\s]','')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stop words from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barely better gabbert significantly better yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fuck ducks angels welcome new niners fans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drafted wrs matt millen probably</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>donehttpsiimgurcom2yz90pmjpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>noo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606469</th>\n",
       "      <td>youre willing splash get 35 hard drive adapter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606470</th>\n",
       "      <td>gtany chance install entire contents disc driv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606471</th>\n",
       "      <td>probably happened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606472</th>\n",
       "      <td>think disappointment came delay ps version rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606473</th>\n",
       "      <td>dishonored 12 looked like arse hell sacrificin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>606474 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      txt\n",
       "0       barely better gabbert significantly better yea...\n",
       "1               fuck ducks angels welcome new niners fans\n",
       "2                        drafted wrs matt millen probably\n",
       "3                            donehttpsiimgurcom2yz90pmjpg\n",
       "4                                                     noo\n",
       "...                                                   ...\n",
       "606469  youre willing splash get 35 hard drive adapter...\n",
       "606470  gtany chance install entire contents disc driv...\n",
       "606471                                  probably happened\n",
       "606472  think disappointment came delay ps version rea...\n",
       "606473  dishonored 12 looked like arse hell sacrificin...\n",
       "\n",
       "[606474 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df['txt'] = df[\"txt\"].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Apply NLTK’s PorterStemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bare better gabbert significantli better year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fuck duck angel welcom new niner fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>draft wr matt millen probabl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>donehttpsiimgurcom2yz90pmjpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>noo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606469</th>\n",
       "      <td>your will splash get 35 hard drive adapt 6tb h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606470</th>\n",
       "      <td>gtani chanc instal entir content disc drive al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606471</th>\n",
       "      <td>probabl happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606472</th>\n",
       "      <td>think disappoint came delay ps version realli ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606473</th>\n",
       "      <td>dishonor 12 look like ars hell sacrif 60 fp fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>606474 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      txt\n",
       "0       bare better gabbert significantli better year ...\n",
       "1                    fuck duck angel welcom new niner fan\n",
       "2                            draft wr matt millen probabl\n",
       "3                            donehttpsiimgurcom2yz90pmjpg\n",
       "4                                                     noo\n",
       "...                                                   ...\n",
       "606469  your will splash get 35 hard drive adapt 6tb h...\n",
       "606470  gtani chanc instal entir content disc drive al...\n",
       "606471                                     probabl happen\n",
       "606472  think disappoint came delay ps version realli ...\n",
       "606473  dishonor 12 look like ars hell sacrif 60 fp fo...\n",
       "\n",
       "[606474 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def stem_sentences(sentence):\n",
    "    tokens = sentence.split()\n",
    "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "df['txt'] = df['txt'].apply(stem_sentences)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_games               435540\n",
       "sports                    145823\n",
       "science_and_technology     25111\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change diagnosis name to target the better represent the outcome of the model data\n",
    "df_cat = df_cat.rename(columns={'cat': 'target'})\n",
    "#Check to see what the balance is between Benign and Malignant tumor diagnosis.\n",
    "df_cat['target'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "606469    0\n",
       "606470    0\n",
       "606471    0\n",
       "606472    0\n",
       "606473    0\n",
       "Name: target, Length: 606474, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = df_cat.replace({'target': {'video_games': 0, 'sports': 1,'science_and_technology':2}})\n",
    "df_target = df_cat['target']\n",
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bare better gabbert significantli better year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fuck duck angel welcom new niner fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>draft wr matt millen probabl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>donehttpsiimgurcom2yz90pmjpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>noo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606469</th>\n",
       "      <td>0</td>\n",
       "      <td>your will splash get 35 hard drive adapt 6tb h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606470</th>\n",
       "      <td>0</td>\n",
       "      <td>gtani chanc instal entir content disc drive al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606471</th>\n",
       "      <td>0</td>\n",
       "      <td>probabl happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606472</th>\n",
       "      <td>0</td>\n",
       "      <td>think disappoint came delay ps version realli ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606473</th>\n",
       "      <td>0</td>\n",
       "      <td>dishonor 12 look like ars hell sacrif 60 fp fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>606474 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target                                                txt\n",
       "0            1  bare better gabbert significantli better year ...\n",
       "1            1               fuck duck angel welcom new niner fan\n",
       "2            1                       draft wr matt millen probabl\n",
       "3            1                       donehttpsiimgurcom2yz90pmjpg\n",
       "4            1                                                noo\n",
       "...        ...                                                ...\n",
       "606469       0  your will splash get 35 hard drive adapt 6tb h...\n",
       "606470       0  gtani chanc instal entir content disc drive al...\n",
       "606471       0                                     probabl happen\n",
       "606472       0  think disappoint came delay ps version realli ...\n",
       "606473       0  dishonor 12 look like ars hell sacrif 60 fp fo...\n",
       "\n",
       "[606474 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.concat([df_target,df],axis=1)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424531, 1)\n",
      "(181943, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275858</th>\n",
       "      <td>play game onlin someth specif requir internet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232205</th>\n",
       "      <td>httpswwwfutbincom17squad1736993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601114</th>\n",
       "      <td>liter right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455302</th>\n",
       "      <td>good call thank remind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414248</th>\n",
       "      <td>im buy switch addit joycon pro control zelda c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29618</th>\n",
       "      <td>go blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340146</th>\n",
       "      <td>pleas tri trade thread check muthead forum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427175</th>\n",
       "      <td>saw one edit boss come back php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437231</th>\n",
       "      <td>target best bet take instor preorder far im aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233839</th>\n",
       "      <td>dembel play ligu 1 sanch play benfica man citi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181943 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      txt\n",
       "275858  play game onlin someth specif requir internet ...\n",
       "232205                    httpswwwfutbincom17squad1736993\n",
       "601114                                        liter right\n",
       "455302                             good call thank remind\n",
       "414248  im buy switch addit joycon pro control zelda c...\n",
       "...                                                   ...\n",
       "29618                                             go blue\n",
       "340146         pleas tri trade thread check muthead forum\n",
       "427175                    saw one edit boss come back php\n",
       "437231  target best bet take instor preorder far im aw...\n",
       "233839  dembel play ligu 1 sanch play benfica man citi...\n",
       "\n",
       "[181943 rows x 1 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_column = ['target'] \n",
    "predictors = list(set(list(df_new.columns))-set(target_column))\n",
    "\n",
    "X = df_new[predictors]\n",
    "y = df_new[target_column].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.30, random_state=40)\n",
    "print(X_train.shape); print(X_test.shape)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ngram_Vectorizer(reviews_train, reviews_test):\n",
    "    tfidf = TfidfVectorizer(max_features=500,lowercase=False)\n",
    "    tfidf.fit(reviews_train)\n",
    "    feature_names = tfidf.get_feature_names()\n",
    "    reviews_train = tfidf.transform(reviews_train).toarray()\n",
    "    reviews_test = tfidf.transform(reviews_test).toarray()\n",
    "    return reviews_train, reviews_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# create object\n",
    "tfidf = TfidfVectorizer(lowercase=False)\n",
    "  \n",
    "# get tf-df values\n",
    "X_train_tfidf,X_test_tfidf = Ngram_Vectorizer(X_train['txt'], X_test['txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.57301902\n",
      "Iteration 2, loss = 0.54388044\n",
      "Iteration 3, loss = 0.52078308\n",
      "Iteration 4, loss = 0.49397843\n",
      "Iteration 5, loss = 0.46594771\n",
      "Iteration 6, loss = 0.43901589\n",
      "Iteration 7, loss = 0.41443792\n",
      "Iteration 8, loss = 0.39281050\n",
      "Iteration 9, loss = 0.37552116\n",
      "Iteration 10, loss = 0.36033432\n",
      "Iteration 11, loss = 0.34839983\n",
      "Iteration 12, loss = 0.33812854\n",
      "Iteration 13, loss = 0.33058943\n",
      "Iteration 14, loss = 0.32104865\n",
      "Iteration 15, loss = 0.31457994\n",
      "Iteration 16, loss = 0.30820751\n",
      "Iteration 17, loss = 0.30267449\n",
      "Iteration 18, loss = 0.29930372\n",
      "Iteration 19, loss = 0.29394953\n",
      "Iteration 20, loss = 0.28945521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dan35\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "# Use MLP neural networkk classifier with 500,150 layers and 20 max iterations\n",
    "mlp = MLPClassifier(hidden_layer_sizes=([500,150]),verbose=True,max_iter=20)\n",
    "mlp.fit(X_train_tfidf,y_train.ravel())\n",
    "\n",
    "#predict_train = mlp.predict(X_train_tfidf[:,1])\n",
    "#predict_test = mlp.predict(X_test_tfidf[:,1])\n",
    "predict_train = mlp.predict(X_train_tfidf)\n",
    "predict_test = mlp.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[298416   6037    424]\n",
      " [ 36610  65360    106]\n",
      " [  5005    269  12304]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93    304877\n",
      "           1       0.91      0.64      0.75    102076\n",
      "           2       0.96      0.70      0.81     17578\n",
      "\n",
      "    accuracy                           0.89    424531\n",
      "   macro avg       0.92      0.77      0.83    424531\n",
      "weighted avg       0.89      0.89      0.88    424531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train,predict_train))\n",
    "print(classification_report(y_train,predict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[113985  14483   2195]\n",
      " [ 27679  15499    569]\n",
      " [  4493    704   2336]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82    130663\n",
      "           1       0.51      0.35      0.42     43747\n",
      "           2       0.46      0.31      0.37      7533\n",
      "\n",
      "    accuracy                           0.72    181943\n",
      "   macro avg       0.58      0.51      0.54    181943\n",
      "weighted avg       0.70      0.72      0.71    181943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predict_test))\n",
    "print(classification_report(y_test,predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras to do a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras specific\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# one hot encode outputs\n",
    "y_train1 = to_categorical(y_train)\n",
    "y_test1 = to_categorical(y_test)\n",
    "\n",
    "count_classes = y_test1.shape[1]\n",
    "print(count_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, activation='relu', input_shape=(500,)))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424531, 500)\n",
      "(424531, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf.shape)\n",
    "print(y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3538/3538 [==============================] - 11s 3ms/step - loss: 0.5734 - accuracy: 0.7551\n",
      "Epoch 2/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.5459 - accuracy: 0.7665\n",
      "Epoch 3/50\n",
      "3538/3538 [==============================] - 9s 2ms/step - loss: 0.5235 - accuracy: 0.7766\n",
      "Epoch 4/50\n",
      "3538/3538 [==============================] - 7s 2ms/step - loss: 0.4967 - accuracy: 0.7878\n",
      "Epoch 5/50\n",
      "3538/3538 [==============================] - 9s 2ms/step - loss: 0.4673 - accuracy: 0.8002\n",
      "Epoch 6/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.4379 - accuracy: 0.8115\n",
      "Epoch 7/50\n",
      "3538/3538 [==============================] - 11s 3ms/step - loss: 0.4113 - accuracy: 0.8220\n",
      "Epoch 8/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.3890 - accuracy: 0.8304\n",
      "Epoch 9/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.3703 - accuracy: 0.8378\n",
      "Epoch 10/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.3548 - accuracy: 0.8445\n",
      "Epoch 11/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.3417 - accuracy: 0.8508\n",
      "Epoch 12/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.3300 - accuracy: 0.8561\n",
      "Epoch 13/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.3205 - accuracy: 0.8603\n",
      "Epoch 14/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.3114 - accuracy: 0.8647\n",
      "Epoch 15/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.3028 - accuracy: 0.8687\n",
      "Epoch 16/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2961 - accuracy: 0.8719\n",
      "Epoch 17/50\n",
      "3538/3538 [==============================] - 9s 2ms/step - loss: 0.2893 - accuracy: 0.8753\n",
      "Epoch 18/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2843 - accuracy: 0.8777\n",
      "Epoch 19/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2786 - accuracy: 0.8802\n",
      "Epoch 20/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2731 - accuracy: 0.8828\n",
      "Epoch 21/50\n",
      "3538/3538 [==============================] - 10s 3ms/step - loss: 0.2705 - accuracy: 0.8839\n",
      "Epoch 22/50\n",
      "3538/3538 [==============================] - 9s 2ms/step - loss: 0.2662 - accuracy: 0.8860\n",
      "Epoch 23/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2621 - accuracy: 0.8880\n",
      "Epoch 24/50\n",
      "3538/3538 [==============================] - 9s 2ms/step - loss: 0.2595 - accuracy: 0.8890\n",
      "Epoch 25/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2567 - accuracy: 0.8899\n",
      "Epoch 26/50\n",
      "3538/3538 [==============================] - 9s 2ms/step - loss: 0.2543 - accuracy: 0.8912\n",
      "Epoch 27/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2520 - accuracy: 0.8924\n",
      "Epoch 28/50\n",
      "3538/3538 [==============================] - 10s 3ms/step - loss: 0.2495 - accuracy: 0.8932\n",
      "Epoch 29/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2484 - accuracy: 0.8939\n",
      "Epoch 30/50\n",
      "3538/3538 [==============================] - 10s 3ms/step - loss: 0.2468 - accuracy: 0.8945\n",
      "Epoch 31/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2440 - accuracy: 0.8956\n",
      "Epoch 32/50\n",
      "3538/3538 [==============================] - 9s 2ms/step - loss: 0.2433 - accuracy: 0.8961\n",
      "Epoch 33/50\n",
      "3538/3538 [==============================] - 9s 2ms/step - loss: 0.2417 - accuracy: 0.8966\n",
      "Epoch 34/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2417 - accuracy: 0.8966\n",
      "Epoch 35/50\n",
      "3538/3538 [==============================] - 9s 2ms/step - loss: 0.2394 - accuracy: 0.8975\n",
      "Epoch 36/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2389 - accuracy: 0.8978\n",
      "Epoch 37/50\n",
      "3538/3538 [==============================] - 11s 3ms/step - loss: 0.2371 - accuracy: 0.8984\n",
      "Epoch 38/50\n",
      "3538/3538 [==============================] - 9s 2ms/step - loss: 0.2362 - accuracy: 0.8986\n",
      "Epoch 39/50\n",
      "3538/3538 [==============================] - 9s 3ms/step - loss: 0.2350 - accuracy: 0.8992\n",
      "Epoch 40/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2348 - accuracy: 0.8993\n",
      "Epoch 41/50\n",
      "3538/3538 [==============================] - 9s 3ms/step - loss: 0.2336 - accuracy: 0.8996\n",
      "Epoch 42/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2326 - accuracy: 0.9001\n",
      "Epoch 43/50\n",
      "3538/3538 [==============================] - 9s 2ms/step - loss: 0.2319 - accuracy: 0.9002\n",
      "Epoch 44/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2314 - accuracy: 0.9006\n",
      "Epoch 45/50\n",
      "3538/3538 [==============================] - 9s 2ms/step - loss: 0.2300 - accuracy: 0.9009\n",
      "Epoch 46/50\n",
      "3538/3538 [==============================] - 9s 3ms/step - loss: 0.2304 - accuracy: 0.9007\n",
      "Epoch 47/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2293 - accuracy: 0.9012\n",
      "Epoch 48/50\n",
      "3538/3538 [==============================] - 9s 3ms/step - loss: 0.2285 - accuracy: 0.9014\n",
      "Epoch 49/50\n",
      "3538/3538 [==============================] - 8s 2ms/step - loss: 0.2274 - accuracy: 0.9018\n",
      "Epoch 50/50\n",
      "3538/3538 [==============================] - 9s 3ms/step - loss: 0.2283 - accuracy: 0.9015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ce82863c40>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "model.fit(X_train_tfidf, y_train1, epochs=50,batch_size=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2188085913658142\n",
      "Test accuracy: 0.9053167104721069\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train_tfidf, y_train1, verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.6663546562194824\n",
      "Test accuracy: 0.7230781316757202\n"
     ]
    }
   ],
   "source": [
    "score1 = model.evaluate(X_test_tfidf, y_test1, verbose = 0) \n",
    "\n",
    "print('Test loss:', score1[0]) \n",
    "print('Test accuracy:', score1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Neural Network Image Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set that the color channel will be first\n",
    "K.set_image_data_format(\"channels_last\")\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set image information\n",
    "channels = 1\n",
    "height = 28\n",
    "width = 28\n",
    "\n",
    "#Load data and target from MNIST data\n",
    "(data_train, target_train),(data_test, target_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training image data into features\n",
    "data_train = data_train.reshape(data_train.shape[0],height, width,channels)\n",
    "\n",
    "data_test = data_test.reshape(data_test.shape[0],height, width,channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale pixel intensity to be between 0 and 1\n",
    "features_train = data_train/255\n",
    "features_test = data_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode target\n",
    "target_train = np_utils.to_categorical(target_train)\n",
    "target_test = np_utils.to_categorical(target_test)\n",
    "number_of_classes = target_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Neural Network\n",
    "network = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add convolutional layer with 64 filters, a 5x5 window, and ReLU activation function\n",
    "network.add(Conv2D(filters=64,\n",
    "                  kernel_size=(5,5),\n",
    "                  input_shape=(height,width,channels),\n",
    "                  activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add max pooling layer with a 2x2 window\n",
    "network.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add layer to flatten input\n",
    "network.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fully connected layer with a softmax activation function\n",
    "network.add(Dense(number_of_classes,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile network\n",
    "network.compile(loss='categorical_crossentropy',\n",
    "               optimizer='rmsprop',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60/60 [==============================] - 16s 263ms/step - loss: 0.5935 - accuracy: 0.8374 - val_loss: 0.2787 - val_accuracy: 0.9212\n",
      "Epoch 2/2\n",
      "60/60 [==============================] - 15s 246ms/step - loss: 0.2317 - accuracy: 0.9321 - val_loss: 0.1774 - val_accuracy: 0.9496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a7d1002e0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Neural Network\n",
    "network.fit(features_train,\n",
    "           target_train,\n",
    "           epochs=2,\n",
    "           verbose=1,\n",
    "           batch_size=1000,\n",
    "           validation_data=(features_test,target_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1773950308561325\n",
      "Test accuracy: 0.9495999813079834\n"
     ]
    }
   ],
   "source": [
    "score = network.evaluate(features_test, target_test, verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
